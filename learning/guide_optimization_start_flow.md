# ç”¨æˆ·ç‚¹å‡»"å¼€å§‹ä¼˜åŒ–"åçš„æ‰§è¡Œæµç¨‹ä¸å»¶è¿Ÿåˆ†æ

æœ¬æ–‡æ¡£è¯¦ç»†è®²è§£ç”¨æˆ·ç‚¹å‡»"å¼€å§‹ä¼˜åŒ–"æŒ‰é’®åçš„å®Œæ•´æ‰§è¡Œæµç¨‹ï¼Œå¹¶åˆ†æå¯¼è‡´é•¿æ—¶é—´ç­‰å¾…çš„å»¶è¿Ÿç“¶é¢ˆã€‚

---

## ğŸ“Š æ•´ä½“æ‰§è¡Œæµç¨‹æ¦‚è§ˆ

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant Landing as LandingPage
    participant App as App.tsx
    participant Chat as ChatPanel
    participant API as Backend API
    participant Plan as PlanAgent
    participant LLM as LLM API
    
    User->>Landing: ç‚¹å‡»"å¼€å§‹ä¼˜åŒ–"æŒ‰é’®
    Landing->>App: onStart(resume, jd, file)
    App->>App: è®¾ç½®åˆå§‹çŠ¶æ€
    App->>App: setPhase("workspace")
    
    Note over User,App: â±ï¸ ~å³æ—¶ (æ¯«ç§’çº§)
    
    App->>Chat: æ¸²æŸ“ ChatPanel
    Chat->>Chat: useEffect è§¦å‘ initializeWorkflow()
    
    Chat->>API: createSession(resume)
    API->>Chat: session_id
    
    Note over User,API: â±ï¸ ~1-2ç§’
    
    rect rgb(255, 230, 230)
        Note over Chat,LLM: ğŸ”´ ä¸»è¦å»¶è¿ŸåŒºåŸŸ (60-90ç§’)
        Chat->>API: generatePlanWithProgress(session_id, userIntent)
        API->>Plan: generate_plan_with_progress()
        Plan->>LLM: OpenAI API è°ƒç”¨
        LLM-->>Plan: è¿”å› TaskList JSON
        Plan-->>API: TaskList
        API-->>Chat: SSE è¿›åº¦äº‹ä»¶ + TaskList
    end
    
    Chat->>API: guideInit(session_id)
    API->>LLM: ç”Ÿæˆå¼€åœºç™½
    LLM-->>API: å¼€åœºç™½å†…å®¹
    API-->>Chat: GuideResponse
    
    Note over User,LLM: â±ï¸ ~3-5ç§’
    
    Chat->>User: æ˜¾ç¤ºä»»åŠ¡åˆ—è¡¨å’Œå¼€åœºç™½
```

---

## ğŸ” å„é˜¶æ®µè¯¦ç»†åˆ†æ

### é˜¶æ®µ 1ï¼šå‰ç«¯è§¦å‘ï¼ˆæ¯«ç§’çº§ï¼‰

```mermaid
flowchart LR
    subgraph "LandingPage.tsx"
        A["ç”¨æˆ·ç‚¹å‡»<br/>'å¼€å§‹ä¼˜åŒ–'æŒ‰é’®"] --> B["handleStart()"]
        B --> C{"åˆ¤æ–­è¾“å…¥æ¨¡å¼"}
        C -->|"å†å²ä¼šè¯"| D["æ¢å¤ä¼šè¯"]
        C -->|"PDFæ¨¡å¼"| E["è§£æ PDF"]
        C -->|"å†å²ç®€å†"| F["ä½¿ç”¨å†å²ç®€å†"]
        
        D --> G["onStart(null, '__RESTORE_SESSION__:xxx', null)"]
        E --> H["onStart(resume, jd, file)"]
        F --> H
    end
```

**ä»£ç ä½ç½®**: `web/src/components/LandingPage.tsx` ç¬¬ 161-219 è¡Œ

```typescript
const handleStart = async () => {
  // å†å²ä¼šè¯æ¨¡å¼ - ç›´æ¥æ¢å¤ä¼šè¯
  if (inputMode === 'history' && selectedSession) {
    onStart(null, '__RESTORE_SESSION__:' + selectedSession.id, null);
    return;
  }
  
  // å†å²ç®€å†æ¨¡å¼
  if (inputMode === 'history' && selectedResume) {
    onStart(selectedResume, jd, null);
    return;
  }
  
  // PDFæ¨¡å¼
  if (inputMode === 'pdf' && file) {
    const resume = await parseResumeWithProgress(file, handleProgressEvent);
    onStart(resume, jd, file);
  }
};
```

---

### é˜¶æ®µ 2ï¼šApp.tsx çŠ¶æ€è®¾ç½®ï¼ˆæ¯«ç§’çº§ï¼‰

```mermaid
flowchart TD
    A["App.tsx<br/>handleStart()"] --> B["æ¸…é™¤æ—§ä¼šè¯çŠ¶æ€"]
    B --> C["setResumeData(resume)"]
    C --> D["setUserIntent(jd)"]
    D --> E["setMessages([æ¬¢è¿æ¶ˆæ¯])"]
    E --> F["setPhase('workspace')"]
    F --> G["æ¸²æŸ“ WorkspaceLayout"]
```

**ä»£ç ä½ç½®**: `web/src/App.tsx` ç¬¬ 59-124 è¡Œ

```typescript
const handleStart = async (resume, jd, file) => {
  // æ¸…é™¤æ—§ä¼šè¯çŠ¶æ€ï¼Œç¡®ä¿åˆ›å»ºæ–°ä¼šè¯
  setSessionId(null);
  setTaskList([]);
  setCurrentTaskIdx(0);

  // è®¾ç½®æ–°ä¼šè¯çš„åˆå§‹çŠ¶æ€
  setResumeData(resume);
  setUserIntent(jd);
  
  // æ·»åŠ æ¬¢è¿æ¶ˆæ¯
  setMessages([{
    role: "assistant",
    content: "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„ç®€å†åŠ©æ‰‹ã€‚æ­£åœ¨ä¸ºä½ ç”Ÿæˆä¼˜åŒ–è®¡åˆ’..."
  }]);

  // è¿›å…¥å·¥ä½œåŒº
  setPhase("workspace");
};
```

---

### é˜¶æ®µ 3ï¼šChatPanel åˆå§‹åŒ–å·¥ä½œæµï¼ˆ60-90ç§’ ğŸ”´ï¼‰

è¿™æ˜¯**ä¸»è¦å»¶è¿Ÿæ¥æº**ï¼

```mermaid
flowchart TD
    subgraph "ChatPanel.tsx - initializeWorkflow()"
        A["useEffect è§¦å‘"] --> B["createSession()"]
        B -->|"~1-2ç§’"| C["è·å– session_id"]
        
        C --> D["generatePlanWithProgress()"]
        
        subgraph "ğŸ”´ ä¸»è¦å»¶è¿Ÿ (60-90ç§’)"
            D --> E["å‘èµ· SSE è¿æ¥"]
            E --> F["PlanAgent.generate_plan_with_progress()"]
            F --> G["åå°çº¿ç¨‹è°ƒç”¨ generate_plan()"]
            G --> H["OpenAI API è°ƒç”¨"]
            H --> I["ç­‰å¾… LLM è¿”å›"]
            I --> J["è§£æ TaskList"]
        end
        
        J --> K["guideInit()"]
        K -->|"~3-5ç§’"| L["æ˜¾ç¤ºå¼€åœºç™½"]
    end
    
    style D fill:#ff6b6b
    style E fill:#ff6b6b
    style F fill:#ff6b6b
    style G fill:#ff6b6b
    style H fill:#ff6b6b
    style I fill:#ff6b6b
    style J fill:#ff6b6b
```

**ä»£ç ä½ç½®**: `web/src/components/ChatPanel.tsx` ç¬¬ 123-208 è¡Œ

```typescript
const initializeWorkflow = async () => {
  setIsLoading(true);
  try {
    // 1. åˆ›å»ºä¼šè¯ (~1-2ç§’)
    const sid = await createSession(resumeData);
    setSessionId(sid);

    // 2. ğŸ”´ ç”Ÿæˆè®¡åˆ’ (60-90ç§’ï¼)
    const planResponse = await generatePlanWithProgress(
      sid, 
      userIntent,
      (event: PlanProgressEvent) => {
        // è¿›åº¦å›è°ƒï¼šæ›´æ–°è¿›åº¦æ¡
        if (event.stage === "analyzing") {
          // æ›´æ–°è¿›åº¦æ¶ˆæ¯...
        }
      }
    );
    
    setTaskList(planResponse.tasks);

    // 3. è°ƒç”¨å¼€åœºç™½ (~3-5ç§’)
    const openingResponse = await guideInit(sid);
    setMessages(prev => [...prev, {
      role: "assistant",
      content: openingResponse.reply
    }]);
  } finally {
    setIsLoading(false);
  }
};
```

---

## ğŸ”´ å»¶è¿Ÿç“¶é¢ˆï¼šPlanAgent.generate_plan()

### ç“¶é¢ˆä½ç½®

```mermaid
flowchart TD
    subgraph "api.py"
        A["POST /session/{id}/plan_stream"] --> B["PlanAgent()"]
    end
    
    subgraph "plan_agent.py - generate_plan_with_progress()"
        B --> C["åˆ›å»ºåå°çº¿ç¨‹"]
        C --> D["worker() å‡½æ•°"]
        D --> E["generate_plan()"]
        
        subgraph "ğŸ”´ é˜»å¡è°ƒç”¨"
            E --> F["client.chat.completions.create()"]
            F --> G["æµå¼æ”¶é›†å“åº”"]
            G --> H["TaskList.model_validate_json()"]
        end
        
        H --> I["è¿”å› TaskList"]
    end
    
    J["ä¼ªè¿›åº¦æ¨é€"] -.-> A
    
    style F fill:#ff6b6b
    style G fill:#ff6b6b
```

**ä»£ç ä½ç½®**: `backend/plan_agent.py` ç¬¬ 216-287 è¡Œ

```python
def generate_plan_with_progress(self, user_intent: str, resume: Resume):
    """å¸¦è¿›åº¦åé¦ˆçš„è®¡åˆ’ç”Ÿæˆï¼ˆä¼ªè¿›åº¦ï¼‰"""
    result = {"plan": None, "error": None}
    
    # ğŸ”´ åå°çº¿ç¨‹è°ƒç”¨çœŸå®çš„ LLM
    def worker():
        try:
            result["plan"] = self.generate_plan(user_intent, resume)  # é˜»å¡ï¼
        except Exception as e:
            result["error"] = str(e)
    
    thread = threading.Thread(target=worker)
    thread.start()
    
    # ä¼ªè¿›åº¦é˜¶æ®µï¼ˆç­‰å¾… LLM æœŸé—´æ˜¾ç¤ºå‡è¿›åº¦ï¼‰
    progress_steps = [
        (2, 5, "æ­£åœ¨å‡†å¤‡åˆ†æ..."),
        (5, 15, "AIæ­£åœ¨è¯»å–ç®€å†å†…å®¹..."),
        (15, 35, "AIæ­£åœ¨æ·±åº¦åˆ†æç®€å†å’ŒèŒä½åŒ¹é…åº¦..."),
        (30, 55, "AIæ­£åœ¨è¯†åˆ«ä¼˜åŒ–æœºä¼š..."),
        (50, 75, "æ­£åœ¨ç”Ÿæˆä¼˜åŒ–æ–¹æ¡ˆ..."),
        (70, 90, "æ­£åœ¨éªŒè¯å’Œæ•´ç†..."),
    ]
    
    # ç­‰å¾…çº¿ç¨‹å®Œæˆï¼ˆæœ€å¤š90ç§’ï¼‰
    thread.join(timeout=90)
```

### generate_plan() çš„çœŸå®å»¶è¿Ÿ

```python
def generate_plan(self, user_intent: str, resume: Resume) -> TaskList:
    # ğŸ”´ è¿™é‡Œæ˜¯çœŸæ­£çš„é˜»å¡ç‚¹ï¼
    response = self.client.chat.completions.create(
        model=self.model,      # "Pro/deepseek-ai/DeepSeek-V3.2"
        messages=messages,
        response_format={"type": "json_object"},
        stream=True  # è™½ç„¶æ˜¯æµå¼ï¼Œä½†è¦ç­‰æ‰€æœ‰ chunk æ”¶å®Œ
    )
    
    # æ”¶é›†æ‰€æœ‰ chunk
    content = ""
    for chunk in response:
        if chunk.choices and chunk.choices[0].delta.content:
            content += chunk.choices[0].delta.content
    
    return TaskList.model_validate_json(content)
```

---

## ğŸ“Š å»¶è¿Ÿæ—¶é—´åˆ†è§£

| é˜¶æ®µ               | è€—æ—¶       | å æ¯”     | ä½ç½®                            |
| ------------------ | ---------- | -------- | ------------------------------- |
| å‰ç«¯çŠ¶æ€åˆ‡æ¢       | ~10ms      | <1%      | `LandingPage.tsx` â†’ `App.tsx`   |
| åˆ›å»ºä¼šè¯ API       | ~1-2s      | ~2%      | `POST /session/create`          |
| **ç”Ÿæˆè®¡åˆ’ (LLM)** | **60-90s** | **~95%** | `PlanAgent.generate_plan()`     |
| ç”Ÿæˆå¼€åœºç™½ (LLM)   | ~3-5s      | ~3%      | `GuideAgent.generate_opening()` |

### å¯è§†åŒ–

```mermaid
pie title å»¶è¿Ÿæ—¶é—´åˆ†å¸ƒ
    "PlanAgent LLM è°ƒç”¨" : 85
    "GuideAgent å¼€åœºç™½" : 10
    "åˆ›å»ºä¼šè¯" : 4
    "å‰ç«¯çŠ¶æ€åˆ‡æ¢" : 1
```

---

## ğŸ”§ ä¸ºä»€ä¹ˆ PlanAgent è¿™ä¹ˆæ…¢ï¼Ÿ

### åŸå› åˆ†æ

1. **å¤æ‚çš„ System Prompt**
   - `_get_system_prompt()` ç”Ÿæˆçš„ prompt éå¸¸é•¿ï¼ˆ~5000+ tokensï¼‰
   - åŒ…å«è¯¦ç»†çš„å­¦ç”Ÿé¡¹ç›®ç­–ç•¥ã€è¯Šæ–­ç­–ç•¥ã€goal æ¨¡æ¿ç­‰

2. **å¤æ‚çš„è¾“å…¥**
   - å®Œæ•´çš„ Resume JSON ä½œä¸ºè¾“å…¥ï¼ˆå¯èƒ½ ~2000+ tokensï¼‰
   - ç”¨æˆ·çš„ Job Descriptionï¼ˆå¯èƒ½ ~500+ tokensï¼‰

3. **å¤æ‚çš„è¾“å‡º**
   - éœ€è¦ç”Ÿæˆç»“æ„åŒ–çš„ TaskList JSON
   - æ¯ä¸ª Task åŒ…å« sectionã€diagnosisã€goalã€strategy ç­‰å­—æ®µ

4. **æ¨¡å‹é€‰æ‹©**
   - ä½¿ç”¨ `Pro/deepseek-ai/DeepSeek-V3.2`ï¼ˆé«˜è´¨é‡ä½†è¾ƒæ…¢ï¼‰

```mermaid
flowchart LR
    subgraph "è¾“å…¥"
        A["System Prompt<br/>~5000 tokens"]
        B["Resume JSON<br/>~2000 tokens"]
        C["Job Description<br/>~500 tokens"]
    end
    
    subgraph "LLM"
        D["DeepSeek-V3.2"]
    end
    
    subgraph "è¾“å‡º"
        E["TaskList JSON<br/>~1000 tokens"]
    end
    
    A --> D
    B --> D
    C --> D
    D --> E
    
    style D fill:#ff6b6b
```

---

## ğŸ“ ä»£ç ä½ç½®ç´¢å¼•

| ç»„ä»¶                        | æ–‡ä»¶              | è¡Œå·        | æè¿°                       |
| --------------------------- | ----------------- | ----------- | -------------------------- |
| å¼€å§‹æŒ‰é’®                    | `LandingPage.tsx` | 614-627     | "å¼€å§‹ä¼˜åŒ–"æŒ‰é’®             |
| handleStart                 | `LandingPage.tsx` | 161-219     | å¤„ç†å¼€å§‹äº‹ä»¶               |
| App handleStart             | `App.tsx`         | 59-124      | è®¾ç½®çŠ¶æ€å¹¶è¿›å…¥å·¥ä½œåŒº       |
| initializeWorkflow          | `ChatPanel.tsx`   | 123-208     | åˆå§‹åŒ–å·¥ä½œæµ               |
| createSession API           | `api.py`          | 266-292     | åˆ›å»ºä¼šè¯ç«¯ç‚¹               |
| plan_stream API             | `api.py`          | 356-431     | ç”Ÿæˆè®¡åˆ’ç«¯ç‚¹ï¼ˆSSEï¼‰        |
| **generate_plan**           | **plan_agent.py** | **188-214** | **ğŸ”´ LLM è°ƒç”¨ï¼ˆå»¶è¿Ÿç“¶é¢ˆï¼‰** |
| generate_plan_with_progress | plan_agent.py     | 216-287     | ä¼ªè¿›åº¦åŒ…è£…                 |

---

## ğŸ’¡ æ½œåœ¨ä¼˜åŒ–æ–¹å‘

### 1. ç¼“å­˜å·²åˆ†æçš„ç®€å†
å¦‚æœåŒä¸€ä»½ç®€å†ä¹‹å‰åˆ†æè¿‡ï¼Œå¯ä»¥å¤ç”¨ä¹‹å‰çš„ TaskListã€‚

### 2. ç®€åŒ– System Prompt
ç²¾ç®€ `_get_system_prompt()` ä¸­çš„æŒ‡ä»¤ï¼Œå‡å°‘ token æ•°ã€‚

### 3. åˆ†é˜¶æ®µç”Ÿæˆ
å…ˆå¿«é€Ÿç”Ÿæˆç²—ç•¥è®¡åˆ’ï¼Œå†é€æ­¥ç»†åŒ–ã€‚

### 4. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
åœ¨è®¡åˆ’ç”Ÿæˆé˜¶æ®µä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ï¼ˆå¦‚ GPT-3.5 Turboï¼‰ã€‚

### 5. é¢„çƒ­æœºåˆ¶
åœ¨ç”¨æˆ·å¡«å†™ JD æ—¶å°±å¼€å§‹é¢„åŠ è½½æ¨¡å‹ã€‚

---

## ğŸ“š æ€»ç»“

```mermaid
graph LR
    subgraph "ç”¨æˆ·æ„ŸçŸ¥"
        A["ç‚¹å‡»æŒ‰é’®"] --> B["ç­‰å¾… 60-90 ç§’"]
        B --> C["çœ‹åˆ°ä»»åŠ¡åˆ—è¡¨"]
    end
    
    subgraph "å®é™…å»¶è¿Ÿ"
        D["PlanAgent.generate_plan()"]
        D -->|"è°ƒç”¨"| E["LLM API"]
        E -->|"~60-90ç§’"| F["è¿”å› TaskList"]
    end
    
    B -.-> D
    
    style D fill:#ff6b6b
    style E fill:#ff6b6b
```

> [!CAUTION]
> **æ ¸å¿ƒç“¶é¢ˆ**ï¼š`PlanAgent.generate_plan()` ä¸­çš„ LLM API è°ƒç”¨æ˜¯å¯¼è‡´ç”¨æˆ·é•¿æ—¶é—´ç­‰å¾…çš„ä¸»è¦åŸå› ã€‚å°½ç®¡ä½¿ç”¨äº†ä¼ªè¿›åº¦å’Œæµå¼ SSEï¼Œå®é™…çš„ LLM è®¡ç®—æ—¶é—´æ— æ³•å‹ç¼©ã€‚

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [guide_strategy_switching.md](file:///c:/Users/admin/Desktop/ResumeAssistant/learning/guide_strategy_switching.md) - ç­–ç•¥åˆ‡æ¢æœºåˆ¶
- [guide_agent_decision_data_layer.md](file:///c:/Users/admin/Desktop/ResumeAssistant/learning/guide_agent_decision_data_layer.md) - AgentDecision æ•°æ®å±‚æ“ä½œ
- [guide_editor_agent_execution.md](file:///c:/Users/admin/Desktop/ResumeAssistant/learning/guide_editor_agent_execution.md) - EditorAgent æ‰§è¡Œæœºåˆ¶
